# Индексация кодовой базы с помощью пользовательских эмбеддингов

Этот проект настраивает локальное окружение для индексации кода с использованием пользовательского сервиса эмбеддингов и векторной базы данных Qdrant.

## Обзор системы

Система состоит из двух основных сервисов, управляемых с помощью Docker Compose:

1.  **Qdrant:** Векторная база данных, используемая для хранения и поиска эмбеддингов кода. Она работает в собственном контейнере и предоставляет свой API на порту `6333`.
2.  **Сервис эмбеддингов:** Пользовательское, легковесное FastAPI-приложение, которое обслуживает модель `jina-code-v2`. Оно использует библиотеку `transformers` для генерации эмбеддингов и предоставляет OpenAI-совместимый API на порту `4000`.

## Диаграмма архитектуры

Простая ASCII-диаграмма, иллюстрирующая поток данных:

```
+---------------------------------+
|        Клиент Roo Code          |
| (в вашем IDE, настроен через    |
|  roo-code-config.json)          |
+---------------------------------+
            |
            | 1. POST-запрос кода для эмбеддинга
            v
+---------------------------------+
|    Пользовательский сервис      |
|    FastAPI (Docker, Порт 4000)  |
|---------------------------------|
|   |        Health: /health      |
|   | 2. Обработка с ...          |
|   v                             |
| +-----------------------------+ |
| | jinaai/jina-embeddings-v2-  | |
| | base-code Модель            | |
| +-----------------------------+ |
|   ^                             |
|   | 3. Возврат вектора          |
|   |                             |
+---------------------------------+
            |
            | 4. Возврат OpenAI-совместимого эмбеддинга
            v
+---------------------------------+
|        Клиент Roo Code          |
|    (получает эмбеддинг)         |
+---------------------------------+
            |
            | 5. Сохранение эмбеддинга в...
            v
+---------------------------------+
|      Векторная БД Qdrant        |
|      (Docker, Порт 6333)        |
|      Health: /collections       |
+---------------------------------+

Сервис прогрева: Инициализирует модель при запуске
```

### Объяснение потока данных:

1.  **Roo Code -> FastAPI:** Ваше IDE, используя настройки из `roo-code-config.json`, отправляет фрагмент кода в пользовательский сервис FastAPI на порт `4000`.
2.  **FastAPI -> Модель:** Сервис FastAPI (прослойка) принимает код и передает его модели `jinaai/jina-embeddings-v2-base-code`, которая работает в том же контейнере.
3.  **Модель -> FastAPI:** Модель преобразует код в числовой вектор (эмбеддинг) и отправляет его обратно в сервис.
4.  **FastAPI -> Roo Code:** Сервис оборачивает этот вектор в стандартный JSON-формат и отправляет его обратно в ваше IDE.
5.  **Roo Code -> Qdrant:** Ваше IDE получает эмбеддинг и отправляет его в базу данных Qdrant на порт `6333`, где он сохраняется и индексируется для будущих поисков.

**Дополнительные сервисы:**
- **Сервис прогрева:** Автоматически инициализирует модель при запуске контейнера, отправляя тестовый запрос.
- **Проверки здоровья:** Оба сервиса предоставляют эндпоинты для мониторинга доступности (`/health` для эмбеддингов, `/collections` для Qdrant).

## Как это работает

1.  **Конфигурация Roo Code:**
    *   Указывает `embeddingProvider` на `baseUrl` пользовательского сервиса: `http://localhost:4000/v1`.
    *   Указывает `vectorStore` как `qdrant` и предоставляет его URL: `http://localhost:6333`.

    Ниже приведен пример полного, валидного конфигурационного файла:

    ```json
    {
      "embeddingProvider": "openai",
      "baseUrl": "http://localhost:4000/v1",
      "modelId": "jinaai/jina-embeddings-v2-base-code",
      "embeddingDimension": 768,
      "vectorStore": "qdrant",
      "qdrantUrl": "http://localhost:6333"
    }
    ```

2.  **Генерация эмбеддингов:** Когда Roo Code необходимо сгенерировать эмбеддинг для фрагмента кода, он отправляет запрос на `http://localhost:4000/v1/embeddings`.

3.  **Пользовательский сервис (`embeddings/jina-server`):** Приложение FastAPI получает запрос, использует модель `jinaai/jina-embeddings-v2-base-code` для генерации векторного эмбеддинга и возвращает его в формате, имитирующем API OpenAI.

4.  **Хранение векторов:** Затем Roo Code берет этот эмбеддинг и сохраняет его в локально запущенной базе данных Qdrant.

## Как запустить

Этот проект предлагает два основных метода запуска сервисов в зависимости от вашей операционной системы и требований к производительности. Все операции централизованы через скрипт `./scripts/manage.sh`.

### Вариант 1: Окружение на базе Docker (CPU / CUDA)

Это универсальный, кроссплатформенный метод. Он идеален для стандартной разработки на любой ОС и для производственных сред, особенно с GPU NVIDIA, поскольку Docker может использовать CUDA для ускорения.

-   **Запуск всех сервисов:**
    ```bash
    ./scripts/manage.sh start all
    ```

-   **Остановка всех сервисов:**
    ```bash
    ./scripts/manage.sh stop all
    ```

-   **Перезапуск всех сервисов:**
    ```bash
    ./scripts/manage.sh restart all
    ```

### Вариант 2: Гибридное окружение для macOS (GPU Apple Silicon)

Это специализированная, высокопроизводительная настройка для разработчиков на **macOS с Apple Silicon (M1/M2/M3)**. Она необходима, поскольку Docker на macOS не может получить доступ к GPU хоста (MPS). Этот гибридный подход запускает критически важный сервис `embeddings` нативно на хосте для полного использования GPU, в то время как база данных `qdrant` продолжает работать удобно в Docker.

#### Предварительные требования

У вас должны быть установлены [pyenv](https://github.com/pyenv/pyenv#installation) и [tmux](https://github.com/tmux/tmux/wiki/Installing) через Homebrew:
```bash
brew install pyenv tmux
```

#### Одноразовая настройка

Перед первым запуском подготовьте локальное окружение Python одной командой:
```bash
./scripts/manage.sh local setup
```
Этот скрипт автоматизирует:
1.  Установку правильной версии Python через `pyenv`.
2.  Создание локального виртуального окружения (`./venv`).
3.  Установку всех необходимых зависимостей Python.

#### Запуск гибридного окружения

1.  **Запуск Qdrant (в Docker):**
    ```bash
    ./scripts/manage.sh start qdrant
    ```

2.  **Запуск сервиса эмбеддингов (локально на macOS):**
    ```bash
    ./scripts/manage.sh local start
    ```
    Это запустит сервис в фоновой сессии `tmux` с значением семафора `2` (оптимизировано для MPS GPU) и будет логировать весь вывод в `logs/embeddings_local.log`.

#### Управление локальным сервисом

-   **Просмотр логов в реальном времени:**
    Подключитесь к фоновой сессии, чтобы увидеть живой вывод сервиса.
    ```bash
    ./scripts/manage.sh local logs
    ```
    *(Для отключения от просмотра логов нажмите `Ctrl-b` затем `d`)*

-   **Остановка локального сервиса:**
    ```bash
    ./scripts/manage.sh local stop
    ```

-   **Перезапуск локального сервиса:**
    ```bash
    ./scripts/manage.sh local restart
    ```

## Производительность и управление семафором

Стабильность и производительность сервиса критически зависят от управления параллелизмом. Это достигается с помощью `asyncio.Semaphore`.

### Конфигурация семафора
Семафор, определенный в `embeddings/app/app.py`, ограничивает количество одновременных запросов, обрабатываемых моделью.

**Значения по умолчанию:**
- **Docker CPU режим:** Оптимальное значение `8` (рассчитано для 8 ГБ ОЗУ, 4 ядер ЦП)
- **macOS GPU режим (MPS):** Текущее значение по умолчанию `2` (подходит для локального GPU выполнения)

```python
# embeddings/app/app.py
SEMAPHORE_VALUE = int(os.environ.get("SEMAPHORE_VALUE", "4"))  # По умолчанию 4, локальный скрипт переопределяет на 2 для macOS GPU
```

### Результаты производительности
- **Оптимизированная производительность:** Система эффективно использует ресурсы ЦП/GPU в зависимости от режима развертывания.
- **Стабильность памяти:** Потребление памяти оптимизировано для каждого режима развертывания с соответствующими значениями семафора.

### Как настраивать семафор
`SEMAPHORE_VALUE` — это самый важный параметр для настройки производительности.

- **Docker CPU режим:** Используйте `8` для систем с 8 ГБ ОЗУ и 4 ядрами ЦП.
- **macOS GPU режим:** Используйте `2` для оптимальной производительности MPS.
- **Когда изменять:**
  - **Больше RAM:** Вы можете осторожно попробовать увеличить значение (например, до `10` или `12`), чтобы потенциально повысить пропускную способность. Внимательно следите за использованием памяти.
  - **Меньше RAM:** Если вы сталкиваетесь со сбоями OOM, вы **должны** уменьшить это значение (например, до `4` или `6`).
- **Как изменить:** Установите переменную окружения `SEMAPHORE_VALUE` или отредактируйте константу непосредственно в файле [`embeddings/app/app.py`](embeddings/app/app.py:1) и перезапустите сервис.

## Продвинутые возможности

Сервис эмбеддингов включает несколько продвинутых функций для оптимальной производительности и мониторинга:

### Очистка памяти на основе простоя

Когда сервис простаивает 60 секунд, он автоматически запускает агрессивную очистку памяти:
- Сборка мусора Python (`gc.collect()`)
- Очистка кэша PyTorch (MPS/CUDA)
- Освобождение памяти обратно в ОС с помощью `malloc_trim` (Linux/macOS)

### Логирование статистики

Сервис логирует агрегированную статистику каждые 30 секунд во время активной работы:
- Общее количество обработанных запросов
- Среднее и максимальное время ожидания
- Максимальная глубина очереди

### Профилирование памяти

Встроенное профилирование памяти с использованием `tracemalloc` предоставляет детальный анализ использования памяти для каждого запроса, помогая выявлять и разрешать проблемы с памятью.

### Мониторинг здоровья

Сервис предоставляет эндпоинт `/health` для мониторинга доступности сервиса.

## Потребление ресурсов

### Потребление в простое

Когда сервисы запущены, но не обрабатывают запросы, их базовое потребление памяти составляет:

-   **Сервис эмбеддингов (Jina):** ~921 МиБ
-   **База данных Qdrant:** ~261 МиБ

### Потребление под пиковой нагрузкой

Под высокой нагрузкой использование памяти варьируется в зависимости от режима развертывания:

-   **Docker CPU режим (семафор = 8):** Пиковое потребление памяти колеблется в безопасном диапазоне **3-5 ГБ**, предотвращая сбои OOM.
-   **macOS GPU режим (семафор = 2):** Пиковое потребление памяти достигает ~4 ГБ под нагрузкой. После начального прогрева стабилизируется на ~2.7 ГБ для текущей работы.

## Интеграция с Visual Studio Code

Для максимального удобства проект настроен для управления прямо из VS Code с помощью горячих клавиш. Для этого необходимо настроить два файла в конфигурации VS Code.

### 1. Настройка задач (`tasks.json`)

Создайте или обновите файл `tasks.json` в вашей пользовательской директории настроек VS Code.

*   **Путь на macOS:** `~/Library/Application Support/Code/User/tasks.json`
*   **Путь на Windows:** `%APPDATA%\Code\User\tasks.json`
*   **Путь на Linux:** `~/.config/Code/User/tasks.json`

Вставьте в него следующее содержимое, **обязательно заменив** `$HOME/sandbox/mcp` на актуальный путь к вашему проекту:

```json
{
  "version": "2.0.0",
  "tasks": [
    {
      "label": "startall + warmup",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "start", "all"]
    },
    {
      "label": "stopall",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "stop", "all"]
    },
    {
      "label": "restartall",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "restart", "all"]
    },
    {
      "label": "qdrant restart",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "restart", "qdrant"]
    },
    {
      "label": "jina start + warmup",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "start", "jina"]
    },
    {
      "label": "jina stop",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "stop", "jina"]
    },
    {
      "label": "local start",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "local", "start"]
    },
    {
      "label": "local stop",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "local", "stop"]
    },
    {
      "label": "local restart",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "local", "restart"]
    },
    {
      "label": "local logs",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "local", "logs"]
    },
    {
      "label": "local setup",
      "type": "shell",
      "command": "bash",
      "args": ["$HOME/sandbox/mcp/scripts/manage.sh", "local", "setup"]
    },
    {
      "label": "help: embeddings shortcuts",
      "type": "shell",
      "command": "echo",
      "args": [
        "-e",
        "\\033[1mJina/Qdrant — горячие клавиши\\033[0m\\n\\n\\033[1mDocker режим:\\033[0m\\n  ⌘⇧9   startall + warmup      — Запустить Qdrant, Jina и прогреть эмбеддинги\\n  ⌘⇧=   restartall            — Перезапустить все сервисы\\n  ⌘⇧-   stopall               — Остановить Jina и Qdrant\\n  ⌘⇧8   qdrant restart        — Перезапустить Qdrant\\n  ⌘⇧7   jina start + warmup   — Запустить Jina и прогреть\\n  ⌘⇧6   jina stop             — Остановить Jina\\n\\n\\033[1mЛокальный режим (macOS GPU):\\033[0m\\n  ⌘⇧1   local start           — Запустить локальный embeddings сервис\\n  ⌘⇧2   local stop            — Остановить локальный сервис\\n  ⌘⇧3   local restart         — Перезапустить локальный сервис\\n  ⌘⇧4   local logs            — Просмотр логов локального сервиса\\n  ⌘⇧5   local setup           — Настроить локальное окружение\\n\\n  ⌘⇧0   help: embeddings shortcuts  — Показать этот экран\\n\\nПодсказка: команды настраиваются в User Tasks и Keyboard Shortcuts (JSON)."
      ],
      "presentation": {
        "reveal": "always",
        "panel": "dedicated",
        "clear": true
      },
      "problemMatcher": []
    }
  ]
}
```

### 2. Настройка горячих клавиш (`keybindings.json`)

Аналогично, создайте или обновите файл `keybindings.json`.

*   **Путь на macOS:** `~/Library/Application Support/Code/User/keybindings.json`
*   **Путь на Windows:** `%APPDATA%\Code\User\keybindings.json`
*   **Путь на Linux:** `~/.config/Code/User/keybindings.json`

Вставьте в него следующее содержимое:

```json
[
  {
    "key": "cmd+shift+9",
    "command": "workbench.action.tasks.runTask",
    "args": "startall + warmup"
  },
  {
    "key": "cmd+shift+=",
    "command": "workbench.action.tasks.runTask",
    "args": "restartall"
  },
  {
    "key": "cmd+shift+0",
    "command": "workbench.action.tasks.runTask",
    "args": "help: embeddings shortcuts"
  },
  {
    "key": "cmd+shift+-",
    "command": "workbench.action.tasks.runTask",
    "args": "stopall"
  },
  {
    "key": "cmd+shift+8",
    "command": "workbench.action.tasks.runTask",
    "args": "qdrant restart"
  },
  {
    "key": "cmd+shift+7",
    "command": "workbench.action.tasks.runTask",
    "args": "jina start + warmup"
  },
  {
    "key": "cmd+shift+6",
    "command": "workbench.action.tasks.runTask",
    "args": "jina stop"
  },
  {
    "key": "cmd+shift+1",
    "command": "workbench.action.tasks.runTask",
    "args": "local start"
  },
  {
    "key": "cmd+shift+2",
    "command": "workbench.action.tasks.runTask",
    "args": "local stop"
  },
  {
    "key": "cmd+shift+3",
    "command": "workbench.action.tasks.runTask",
    "args": "local restart"
  },
  {
    "key": "cmd+shift+4",
    "command": "workbench.action.tasks.runTask",
    "args": "local logs"
  },
  {
    "key": "cmd+shift+5",
    "command": "workbench.action.tasks.runTask",
    "args": "local setup"
  }
]
```

### Доступные команды (горячие клавиши)

После настройки вы сможете управлять сервисами с помощью следующих сочетаний клавиш (для macOS, замените `cmd` на `ctrl` для Windows/Linux):

#### Команды Docker режима
| Горячая клавиша | Команда                  | Описание                                           |
| --------------- | ------------------------ | -------------------------------------------------- |
| `⌘ + ⇧ + 9`     | `startall + warmup`      | Запустить Qdrant, Jina и прогреть эмбеддинги        |
| `⌘ + ⇧ + =`     | `restartall`             | Перезапустить все сервисы                          |
| `⌘ + ⇧ + -`     | `stopall`                | Остановить Jina и Qdrant                           |
| `⌘ + ⇧ + 8`     | `qdrant restart`         | Перезапустить только Qdrant                        |
| `⌘ + ⇧ + 7`     | `jina start + warmup`    | Запустить только Jina и прогреть                    |
| `⌘ + ⇧ + 6`     | `jina stop`              | Остановить только Jina                             |

#### Команды локального режима (macOS GPU)
| Горячая клавиша | Команда                  | Описание                                           |
| --------------- | ------------------------ | -------------------------------------------------- |
| `⌘ + ⇧ + 1`     | `local start`            | Запустить локальный embeddings сервис              |
| `⌘ + ⇧ + 2`     | `local stop`             | Остановить локальный сервис                        |
| `⌘ + ⇧ + 3`     | `local restart`          | Перезапустить локальный сервис                     |
| `⌘ + ⇧ + 4`     | `local logs`             | Просмотр логов локального сервиса                  |
| `⌘ + ⇧ + 5`     | `local setup`            | Настроить локальное окружение                      |

#### Общие команды
| Горячая клавиша | Команда                  | Описание                                           |
| --------------- | ------------------------ | -------------------------------------------------- |
| `⌘ + ⇧ + 0`     | `help: embeddings shortcuts` | Показать эту справку в терминале VS Code           |
